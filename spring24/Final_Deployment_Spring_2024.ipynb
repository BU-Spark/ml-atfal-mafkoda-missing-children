{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a65b5ea5-f249-4dc1-ba60-f69237e9dfda",
   "metadata": {},
   "source": [
    "DeepFace (Keras) doesn't work with the current conda environment. The parser ueses DeepFace, same as the one from previous semester's face similarity parser. Please load the conda environment related to previous semester's face similarity parser. The face similarity ipynb file has also been added to a separate file for convenience"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2812e24-9b18-48ee-9dca-18adb1ce7ce0",
   "metadata": {},
   "source": [
    "# Initial Setup\n",
    "\n",
    "We've modified code from this github repo [https://github.com/taesungp/swapping-autoencoder-pytorch] and therefore doesn't embed the original github repo.\n",
    "\n",
    "Download the FFHQ512 pretrained model for the Swapping Autoencoder Model from this link. [http://efrosgans.eecs.berkeley.edu/SwappingAutoencoder/swapping_autoencoder_models_and_test_images.zip]\n",
    "(Note: this is a http (not https) address, and you may need to paste in the link URL directly in the address bar for some browsers like Chrome, or download the dataset using wget)\n",
    "\n",
    "There will be multiple folders once this zip file is uncompressed. The one that should be kept is \"ffhq512_pretrained\". Drag this folder into \"spring24/swapping-autoencoder-pytorch/experiments/checkpoints\".\n",
    "\n",
    "In spring24 folder, run `conda env create -f environment.yml` then `conda activate swap-auto-pytorch` to enable the conda environment.\n",
    "\n",
    "As noted in the block above, we were unable to get DeepFace to work with this swap-auto-pytorch conda environment. We're aware that a previous group uses this model for their project. Please load their conda environment if you want to attempt any code under the tag \"Deepface\". For any code under \"Swapping Autoencoder\", use the swap-auto-pytorch conda environment.\n",
    "\n",
    "Variable names:\n",
    "\n",
    "`candidate_directory`: A full path to where the image of the textures should be (candidate images that are hand picked)\n",
    "\n",
    "`image_directory`: A full path to where the image of the structure should be (images of missing people that we want to apply homelessness to)\n",
    "\n",
    "`ouput_file_name`: A file name of the csv that DeepFace will output after matching faces from image_directory to candidate_directory.\n",
    "\n",
    "`parsed_output_file_name`: A file name of the csv that the notebook will output after parsing through output_file_name.\n",
    "\n",
    "`output_dir`: A full path to where the output_file_name is located\n",
    "\n",
    "`parsed_output_dir`: A full path to where the output_file_name is located\n",
    "\n",
    "After auto-encoder runs, run the matplotlib visualizer to see the results\n",
    "\n",
    "The matplotlib visualizer will print the structure image file name and texture image file name. Identify which alpha value looks good and the result will be in the folder spring24/swapping-autoencoder-pytorch/results/ffhq512_pretrained/simpleswapping/.\n",
    "\n",
    "Once you've determined which image looks good, find the image in the folder specified above. The file will be named {structure_image_file_name}\\_{texture_image_file_name}\\_{alpha_value}.png\n",
    "\n",
    "NOTE: When adding to candidate_directory, do not add AI generated images of homeless people. Almost all of them perform extremely poorly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70692372-b294-4b3e-b795-2013a0534ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS DIRECTORY TO WHERE TEXTURES ARE\n",
    "candidate_directory = '/projectnb/sparkgrp/ml-atfal-mafkoda-grp/google_candidate/'\n",
    "# CHANGE THIS DIRECTORY TO NEW SET OF IMAGES FOR STRUCTURE\n",
    "image_directory = '/projectnb/sparkgrp/ml-atfal-mafkoda-grp/missing_children_johndoe_reunited_images_bounding_box/'\n",
    "\n",
    "output_file_name = 'google-trial.csv'\n",
    "output_dir = \"/projectnb/sparkgrp/ml-atfal-mafkoda-grp/simonkye/\" + output_file_name\n",
    "parsed_output_dir = \"/projectnb/sparkgrp/ml-atfal-mafkoda-grp/simonkye/\" + parsed_output_file_name\n",
    "parsed_output_file_name = 'google-parsed_trial.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b5f8e0-2f92-428e-a77a-c9568a1b3ee0",
   "metadata": {},
   "source": [
    "# Deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3d954bd-8482-40b8-aff2-1b9b63dc3573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for both DeepFace & Autoencoder\n",
    "import os\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a78621bc-852a-4994-9107-ca8e084dcd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for DeepFace\n",
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d6eee3-5a5b-4338-84e3-d34187bf5ed0",
   "metadata": {},
   "source": [
    "This block exists as DeepFace keeps a checkpoint of previous inputs, sometimes it will have access to photos that don't exist anymore in the directories specified above. This attempts to remove these checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13158614-f955-4dd0-8384-bd57abf68d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/projectnb/sparkgrp/ml-atfal-mafkoda-grp/candidate_repository'\n",
    "file_list = os.listdir(directory)\n",
    "\n",
    "for file_name in file_list:\n",
    "    if file_name.endswith('.pkl'):\n",
    "        os.remove(os.path.join(directory, file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b48fe6e-2872-429d-9e7f-6254991200a2",
   "metadata": {},
   "source": [
    "This block runs that actual DeepFace model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e12ecd-58a9-48ed-9d70-788533371500",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceRecognition:\n",
    "    def __init__(self, missing_dir, unknown_dir, output_path, model='VGG-Face', metric='euclidean_l2', detector_backend='mtcnn'):\n",
    "        # Initialize the FaceRecognition class with directories, output path, model, metric, and detector backend\n",
    "        self.missing_dir = missing_dir  # Directory of missing persons' images\n",
    "        self.unknown_dir = unknown_dir  # Directory of unknown persons' images\n",
    "        self.output_path = output_path  # Path for the output CSV file\n",
    "        self.model = model  # Face recognition model\n",
    "        self.metric = metric  # Distance metric for comparison\n",
    "        self.detector_backend = detector_backend  # Backend for face detection\n",
    "        # self.metric_col = self.model + \"_\" + self.metric  # Column name for metric in the output DataFrame\n",
    "\n",
    "    def detect_and_match_faces(self):\n",
    "        # Detect and match faces in images from the missing directory\n",
    "        image_paths = glob.glob(os.path.join(self.missing_dir, \"*\"))  # Get all image paths\n",
    "        results = []  # List to store the results\n",
    "        for path in image_paths:\n",
    "            # Check the file extension\n",
    "            ext = os.path.splitext(path)[1].lower()\n",
    "            if ext in [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"]:\n",
    "                # Extract faces from the image\n",
    "                detected_img_objs = DeepFace.extract_faces(path, enforce_detection=False, detector_backend=self.detector_backend)\n",
    "                \n",
    "                if detected_img_objs:\n",
    "                    # Find matches in the unknown directory using DeepFace\n",
    "                    dfs_list = DeepFace.find(\n",
    "                        img_path=path,\n",
    "                        db_path=self.unknown_dir, \n",
    "                        model_name=self.model,\n",
    "                        distance_metric=self.metric,\n",
    "                        enforce_detection=False,\n",
    "                        detector_backend=self.detector_backend\n",
    "                    )\n",
    "\n",
    "                    dfs = dfs_list[0]\n",
    "\n",
    "                    \n",
    "                    dfs['identity'] = dfs['identity'].str.split('/').str.get(-1)\n",
    "                    print(dfs.head())\n",
    "\n",
    "                    # Check if the DataFrame is not empty and append the results\n",
    "                    if not dfs.empty:\n",
    "                        matched_filenames = ', '.join(dfs['identity'].tolist())\n",
    "                        print(matched_filenames)\n",
    "                        # metric_values = ', '.join(map(str, dfs[self.metric_col].tolist()))\n",
    "\n",
    "                        results.append({\n",
    "                            'missing_filename': path,\n",
    "                            'unknowns_matched_filenames': matched_filenames,\n",
    "                            'distance': dfs['distance']\n",
    "                        })\n",
    "\n",
    "        df = pd.DataFrame(results)  # Create DataFrame from results\n",
    "        df.to_csv(self.output_path, index=False)  # Save the results to a CSV file\n",
    "\n",
    "def parse_args():\n",
    "    # Define command line arguments for the script\n",
    "    parser = argparse.ArgumentParser(description='Face recognition')\n",
    "    parser.add_argument('--model', type=str, default='VGG-Face', help='Model to use for Face Recognition')\n",
    "    parser.add_argument('--metric', type=str, default='euclidean_l2', help='Metrics to use for Face Recognition')\n",
    "    parser.add_argument('--missing_dir', required=True, type=str, help='Directory containing images of missing persons')\n",
    "    parser.add_argument('--unknown_dir', required=True, type=str, help='Directory containing images of unknown persons')\n",
    "    parser.add_argument('--output_path', required=True, type=str, help='Path to the output CSV file')\n",
    "    parser.add_argument('--detector_backend', type=str, default='mtcnn', help='Detector backend to use')\n",
    "    return parser.parse_args()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fr = FaceRecognition(\n",
    "        missing_dir=image_directory,\n",
    "        unknown_dir=candidate_directory,\n",
    "        output_path=output_file_name\n",
    "    )\n",
    "    fr.detect_and_match_faces()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e257b16-4141-4503-b7e4-722c8ab18d75",
   "metadata": {},
   "source": [
    "## (After DeepFace Face Similarity)\n",
    "The code block assumes you have the outputs from FaceSimilarity. It finds the closest result that isn't itself. (that's why the < 0.001 check exists) It will use the most similar looking image from the image repository as the structure and the candidate repository as the texture.\n",
    "\n",
    "The following code block exists as the DeepFace model keeps checkpoints in its model leading it to match faces that no longer exist in the candidate_directory or the image_directory. This is why the -checkpoint check exists, so do not name any input file with the string '-checkpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd3ce1ab-6e4b-4e4a-b10d-b43a66c09f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(output_dir)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    row['unknowns_matched_filenames'] = row['unknowns_matched_filenames'].split(', ')\n",
    "    row['missing_filename'] = row['missing_filename'].split('/')[-1]\n",
    "    \n",
    "    # Convert the 'distance' column to a list\n",
    "    data = row['distance']\n",
    "    datapoints = data.split()\n",
    "    df.loc[index, 'valid_found'] = False\n",
    "    best_match = None\n",
    "\n",
    "    for i in range(len(datapoints)):\n",
    "        try:\n",
    "            if float(datapoints[i]) < 0.001:\n",
    "                continue\n",
    "            filename = row['unknowns_matched_filenames'][i - 1]\n",
    "            if '-checkpoint' not in filename:\n",
    "                best_match = filename\n",
    "                df.loc[index, 'valid_found'] = True\n",
    "                break\n",
    "        except ValueError:\n",
    "            break\n",
    "\n",
    "    if best_match is None:\n",
    "        df.loc[index, 'best_match'] = row['missing_filename']\n",
    "    else:\n",
    "        df.loc[index, 'best_match'] = best_match\n",
    "        \n",
    "df.to_csv(parsed_output_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192c0f82-eccf-497b-b8b6-39b6f87fe669",
   "metadata": {},
   "source": [
    "# Swapping Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca0e17-4f12-46b4-a939-35ac761d1932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for both DeepFace & Autoencoder\n",
    "import os\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515ed415-a65a-40cc-84d5-0b616caa210e",
   "metadata": {},
   "source": [
    "## Without DeepFace Similarity\n",
    "The code block below assumes a manually made csv is being used. The only columns needed is 'missing_filename' (structure image file name), 'valid_found' (set to True), and best_match (texture image file name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137369a3-cf84-40de-939d-9b8e38352c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(parsed_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e328ed9-c905-43f2-957b-ba131cf18479",
   "metadata": {},
   "source": [
    "## Auto Swapping Encoder\n",
    "The code block is simply running the python commands needed to run the model as it only uses Python files rather than ipynb files. Therefore, if a user wanted to run the model without generating a csv, they can cd to the swapping-autoencoder-pytorch directory and run the following command.\n",
    "\n",
    "`python -m experiments ffhq512_pretrained test simple_interpolation --input_structure_image [full path to structure image] --input_texture_image [full path to texture image]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45abb2fb-8f11-4198-9631-50b56f8e4fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/projectnb/sparkgrp/ml-atfal-mafkoda-grp/swapping-autoencoder-pytorch\")\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    \n",
    "    missing_filename = row['missing_filename'] \n",
    "    input_structure_image = image_directory + missing_filename\n",
    "    directory_exists = os.path.exists(os.path.dirname(input_structure_image))\n",
    "    best_match_filename = row['best_match']\n",
    "    input_texture_image = candidate_directory + best_match_filename\n",
    "    directory_exists = os.path.exists(os.path.dirname(input_texture_image)) and directory_exists\n",
    "    if not directory_exists:\n",
    "        print(\"invalid directory\")\n",
    "    if not row['valid_found']:\n",
    "        print(\"no valid image found for \" + missing_filename)\n",
    "    else:\n",
    "        command = [\n",
    "            \"python\",\n",
    "            \"-m\",\n",
    "            \"experiments\",\n",
    "            \"ffhq512_pretrained\",\n",
    "            \"test\",\n",
    "            \"simple_interpolation\",\n",
    "            \"--input_structure_image\",\n",
    "            input_structure_image,\n",
    "            \"--input_texture_image\",\n",
    "            input_texture_image\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            subprocess.run(command, check=True)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error executing command: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345508e9-726d-4953-9f77-7d43bcfe6ce9",
   "metadata": {},
   "source": [
    "## Displaying results of Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2fcbdf-8091-453a-951d-44b0dc6b27e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_structure = 0\n",
    "missing_texture = 0\n",
    "missing_results = 0\n",
    "def display_images(image_folder, image_prefix, image_suffix, input_structure_image, input_texture_image):\n",
    "    global missing_structure, missing_texture, missing_results\n",
    "    # Create a figure and grid layout\n",
    "    fig = plt.figure(figsize=(12, 3))\n",
    "    gs = gridspec.GridSpec(1, 7)  # 1 row, 7 columns\n",
    "\n",
    "    # Display the input_structure_image\n",
    "    try: \n",
    "        ax1 = plt.subplot(gs[0, 0])\n",
    "        ax1.imshow(Image.open(input_structure_image))\n",
    "        ax1.axis('off')\n",
    "        ax1.set_title('Structure')\n",
    "    except:\n",
    "        print(f\"File not found: {input_structure_image}\")\n",
    "        missing_structure += 1\n",
    "\n",
    "    # Display the interpolated images\n",
    "    try:\n",
    "        for i in range(5):\n",
    "            image_path = os.path.join(image_folder, f\"{image_prefix}_{image_suffix}_{i*0.25:.2f}.png\")\n",
    "            ax = plt.subplot(gs[0, i+1])\n",
    "            ax.imshow(Image.open(image_path))\n",
    "            ax.axis('off')\n",
    "            ax.set_title(f\"{i*0.25:.2f}\")\n",
    "    except:\n",
    "        print(f\"File not found: {image_prefix}_{image_suffix}_{i*0.25:.2f}.png\")\n",
    "        missing_texture += 1\n",
    "\n",
    "    # Display the input_texture_image\n",
    "    try:\n",
    "        ax7 = plt.subplot(gs[0, 6])\n",
    "        ax7.imshow(Image.open(input_texture_image))\n",
    "        ax7.axis('off')\n",
    "        ax7.set_title('Texture')\n",
    "    except:\n",
    "        print(f\"File not found: {input_texture_image}\")\n",
    "        missing_results += 1\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    if not row['valid_found']:\n",
    "        continue\n",
    "    missing_filename = row['missing_filename'] \n",
    "    input_structure_image = image_directory + missing_filename\n",
    "    directory_exists = os.path.exists(os.path.dirname(input_structure_image))\n",
    "    best_match_filename = row['best_match']\n",
    "    input_texture_image = candidate_directory + best_match_filename\n",
    "    print(input_structure_image)\n",
    "    print(input_texture_image)\n",
    "    directory_exists = os.path.exists(os.path.dirname(input_texture_image)) and directory_exists\n",
    "    if not directory_exists or not row['valid_found']:\n",
    "        print(\"Missing person's file not found or no valid candidate image found!\")\n",
    "    else:\n",
    "        image_folder = \"/projectnb/sparkgrp/ml-atfal-mafkoda-grp/swapping-autoencoder-pytorch/results/ffhq512_pretrained/simpleswapping/\"\n",
    "        image_prefix = row['missing_filename'].replace('.png', '')\n",
    "        image_suffix = row['best_match'].replace('.png', '')\n",
    "        input_structure_image = input_structure_image\n",
    "        input_texture_image = input_texture_image\n",
    "        \n",
    "        display_images(image_folder, image_prefix, image_suffix, input_structure_image, input_texture_image)\n",
    "\n",
    "print(f\"Missing Structures: {missing_structure}\")\n",
    "print(f\"Missing Textures: {missing_texture}\")\n",
    "print(f\"Missing Results: {missing_results}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:swap-auto-pytorch]",
   "language": "python",
   "name": "conda-env-swap-auto-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
